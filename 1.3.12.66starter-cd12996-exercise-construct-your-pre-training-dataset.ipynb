{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: Construct your pre-training dataset\n",
    "\n",
    "When it comes to training language models, selecting the right pre-training dataset is important. In this exercise, we will explore the options available for choosing a pre-training dataset, focusing on four key sources: CommonCrawl, Github, Wikipedia, and the Gutenberg project. These sources provide a wide range of data, making them valuable resources for training language models. If you were tasked with pre-training an LLM, how would you use these datasets and how would you pre-process them (if at all)? Are there other sources you would use?\n",
    "\n",
    "In this exercise, you will construct a fictional pre-training dataset for a fictional task. The goal is to get you thinking about how to construct a pre-training dataset for your own task.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Evaluate the available pre-training datasets\n",
    "\n",
    "Begin by examining the four sources mentioned in the introduction - CommonCrawl, Github, Wikipedia, and the Gutenberg project. Assess the size, quality, and relevance of the data provided by each source for training language models.\n",
    "\n",
    "### CommonCrawl\n",
    "\n",
    "Read about CommonCrawl on its website: https://commoncrawl.org/\n",
    "\n",
    "Question: What is the size of the CommonCrawl dataset?\n",
    "Choices:\n",
    "    * <1 TB\n",
    "    * 10 TB\n",
    "    * 100 TB\n",
    "    * 1 PB+\n",
    "\n",
    "True answer: 1 PB+\n",
    "\n",
    "Question: What is the quality of the CommonCrawl dataset?\n",
    "\n",
    "Choices:\n",
    "    * Highly curated and structured\n",
    "    * Semi-structured and clean\n",
    "    * Unstructured and noisy\n",
    "\n",
    "True answer: Unstructured and noisy\n",
    "\n",
    "### Github\n",
    "\n",
    "Read about the Github dataset on its website: https://www.githubarchive.org/\n",
    "\n",
    "True or false: The Github dataset contains both public and private repositories.\n",
    "\n",
    "Choices:\n",
    "    * True\n",
    "    * False\n",
    "\n",
    "True answer: False, the Github dataset only contains public repositories.\n",
    "\n",
    "### Wikipedia\n",
    "\n",
    "Read about the Wikipedia dataset on its website: https://dumps.wikimedia.org/\n",
    "\n",
    "Question: What formats are the Wikipedia datasets available in?\n",
    "\n",
    "Choices:\n",
    "    * XML\n",
    "    * JSON\n",
    "    * SQL\n",
    "    * All of the above\n",
    "\n",
    "True answer: All of the above\n",
    "\n",
    "\n",
    "### Gutenberg project\n",
    "\n",
    "Read about the Gutenberg project on its website: https://www.gutenberg.org/\n",
    "\n",
    "Question: How many books are in the Gutenberg project dataset?\n",
    "\n",
    "Choices:\n",
    "    * A. at most 10,000\n",
    "    * B. 10,000 - 100,000\n",
    "    * C. 100,000 - 1,000,000\n",
    "    * D. 10,000,000+\n",
    "\n",
    "True answer: B. 10,000 - 100,000. There are over 70,000 books in the Gutenberg project dataset.\n",
    "\n",
    "## Step 2. Select the appropriate datasets\n",
    "\n",
    "Based on the evaluation, choose the datasets that best suit the requirements of pre-training a Language Model (LLM). Consider factors such as the diversity of data, domain-specific relevance, and the specific language model objectives.\n",
    "\n",
    "For your use case, rank the datasets in order of preference. For example, if you were training a language model to generate code, you might rank the datasets as follows:\n",
    "\n",
    "1. Github\n",
    "2. Wikipedia\n",
    "3. CommonCrawl\n",
    "4. Gutenberg project\n",
    "\n",
    "Explain your reasoning for the ranking. For example, you might say that Github is the best dataset because it contains a large amount of code, and the code is structured and clean. You might say that Wikipedia is the second-best dataset because it contains a large amount of text, including some code. You might say that CommonCrawl is the third-best dataset because it contains a large amount of text, but the text is unstructured and noisy. You might say that the Gutenberg project is the worst dataset because it contains text that is not relevant to the task.\n",
    "\n",
    "TODO: Insert ranking quiz\n",
    "\n",
    "Feel free to use the text box below to record your thoughts. You can also use pen and paper, your voice, or any other tool you prefer.\n",
    "\n",
    "TODO: Insert freeform response\n",
    "\n",
    "## Step 3. Pre-process the selected datasets\n",
    "\n",
    "Depending on the nature of the chosen datasets, pre-processing may be required. This step involves cleaning the data, removing irrelevant or noisy content, standardizing formats, and ensuring consistency across the dataset. Discuss how you would pre-process the datasets based on what you have observed.\n",
    "\n",
    "Feel free to use the text box below to record your thoughts. You can also use pen and paper, your voice, or any other tool you prefer.\n",
    "\n",
    "## Step 4. Augment with additional sources\n",
    "\n",
    "Consider whether there are other relevant sources that can be used to augment the selected datasets. These sources could include domain-specific corpora, specialized text collections, or other publicly available text data that aligns with your language model's objectives.\n",
    "\n",
    "Feel free to use the text box below to record your thoughts. You can also use pen and paper, your voice, or any other tool you prefer.\n",
    "\n",
    "TODO: Insert freeform response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
